{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qiaoan/miniconda3/envs/LIU/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from datasets import DatasetDict, Dataset, load_dataset, load_from_disk\n",
    "from transformers import AutoTokenizer\n",
    "from dataprocessor import SamplePreprocessorForFinetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19661\n",
      "{'id': '842e15a0ea54a3bb7f7cf13c8cba28dc', 'qtype': 'FactChecking', 'qsubtype': 'MatchBased', 'instruction': 'You are a data analyst proficient in Python. Your task is to write executable Python code to analyze the table and then answer questions.\\n\\n[Guidelines]\\nYou should act following requirements below:\\n1. based on the question, write out your analytical approach, and then write Python code according to this approach.\\n2. The code needs to be concise and easy to understand, and if necessary, add comments for clarification.\\n3. Code blocks need to strictly start with ```python and end with ```\\n4. Your analysis must be based entirely on the above data. If the user\\'s question is not related to data analysis, please politely refuse.\\n5. You need to generate executable code. If there are results to be presented, please use the print function; if there are charts, please use the matplotlib library to draw them.\\n6. Ensure to load the table with command ```df = pd.read_csv(\\'table.csv\\')```\\n\\n\\nThe generated Python code should follow the format below, and ensure the first two code lines is exactly the same with the following code block:\\n[Python Code Format]\\n```python\\nimport pandas as pd \\ndf = pd.read_csv(\\'table.csv\\')\\n...\\nprint(f\\'Final Answer: {{answer}}\\')\\n```\\n\\nEnsure the final answer is the last line in python code and can only be in the \"print(f\\'Final Answer: {{answer}}\\')\" form, no other from. Ensure variable \"answer\" can only be \"AnswerName1, AnswerName2...\" form, no other form, and \"AnswerName\" can only be a number or entity name, as short as possible, without any explanation.\\n\\n\\nLet\\'s think step by step and then generate python code to analyze table and present the final answer to the question.\\n\\nRead the table below in JSON format:\\n[TABLE] \\n{\"columns\": [\"Year\", \"Single\", \"Chart\", \"Position\"], \"data\": [[1986, \"\\\\\\\\Best of Both Worlds\\\\\\\\\\\\\"\\\\\"\", \"Album Rock Tracks\", 12], [1986, \"\\\\\\\\Dreams\\\\\\\\\\\\\"\\\\\"\", \"Album Rock Tracks\", 6], [1986, \"\\\\\\\\Dreams\\\\\\\\\\\\\"\\\\\"\", \"Billboard Hot 100\", 22], [1986, \"\\\\\\\\Love Walks In\\\\\\\\\\\\\"\\\\\"\", \"Album Rock Tracks\", 4], [1986, \"\\\\\\\\Love Walks In\\\\\\\\\\\\\"\\\\\"\", \"Billboard Hot 100\", 22], [1986, \"\\\\\\\\Summer Nights\\\\\\\\\\\\\"\\\\\"\", \"Album Rock Tracks\", 33], [1986, \"\\\\\\\\Why Can\\'t This Be Love\\\\\\\\\\\\\"\\\\\"\", \"Album Rock Tracks\", 1], [1986, \"\\\\\\\\Why Can\\'t This Be Love\\\\\\\\\\\\\"\\\\\"\", \"Billboard Hot 100\", 3]]}\\n\\nLet\\'s get start!\\nQuestion: How many singles by Van Halen reached the top 10 on the Album Rock Tracks chart in 1986?', 'instruction_type': 'PoT', 'table': '{\"columns\": [\"Year\", \"Single\", \"Chart\", \"Position\"], \"data\": [[1986, \"\\\\\\\\Best of Both Worlds\\\\\\\\\\\\\"\\\\\"\", \"Album Rock Tracks\", 12], [1986, \"\\\\\\\\Dreams\\\\\\\\\\\\\"\\\\\"\", \"Album Rock Tracks\", 6], [1986, \"\\\\\\\\Dreams\\\\\\\\\\\\\"\\\\\"\", \"Billboard Hot 100\", 22], [1986, \"\\\\\\\\Love Walks In\\\\\\\\\\\\\"\\\\\"\", \"Album Rock Tracks\", 4], [1986, \"\\\\\\\\Love Walks In\\\\\\\\\\\\\"\\\\\"\", \"Billboard Hot 100\", 22], [1986, \"\\\\\\\\Summer Nights\\\\\\\\\\\\\"\\\\\"\", \"Album Rock Tracks\", 33], [1986, \"\\\\\\\\Why Can\\'t This Be Love\\\\\\\\\\\\\"\\\\\"\", \"Album Rock Tracks\", 1], [1986, \"\\\\\\\\Why Can\\'t This Be Love\\\\\\\\\\\\\"\\\\\"\", \"Billboard Hot 100\", 3]]}', 'question': 'How many singles by Van Halen reached the top 10 on the Album Rock Tracks chart in 1986?', 'response': 'To answer the question, we need to follow these steps:\\n\\n1. Load the data from the CSV file.\\n2. Filter the data to include only the rows where the \"Chart\" column is \"Album Rock Tracks\".\\n3. Further filter the data to include only the rows where the \"Position\" column is less than or equal to 10.\\n4. Count the number of unique singles that meet these criteria.\\n\\nLet\\'s write the Python code to perform this analysis.\\n\\n```python\\nimport pandas as pd \\ndf = pd.read_csv(\\'table.csv\\')\\n\\n# Filter for Album Rock Tracks chart\\nalbum_rock_tracks = df[df[\\'Chart\\'] == \\'Album Rock Tracks\\']\\n\\n# Filter for positions in the top 10\\ntop_10_singles = album_rock_tracks[album_rock_tracks[\\'Position\\'] <= 10]\\n\\n# Count the number of unique singles\\nunique_top_10_singles = top_10_singles[\\'Single\\'].nunique()\\n\\nanswer = unique_top_10_singles\\nprint(f\\'Final Answer: {answer}\\')\\n```'}\n"
     ]
    }
   ],
   "source": [
    "train_dataset = load_dataset(\"json\", data_files=\"/home/qiaoan/data/TableInstruct/TableInstruct_instructions.jsonl\", split=\"train\")\n",
    "print(len(train_dataset))\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19655/19655 [02:16<00:00, 144.46it/s]\n",
      "Filter (num_proc=32): 100%|██████████| 19655/19655 [02:05<00:00, 156.67 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19604\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"/home/qiaoan/data/Qwen2-7B-Instruct\")\n",
    "preprocessor = SamplePreprocessorForFinetune(tokenizer, max_length=3000)\n",
    "samples = []\n",
    "from tqdm import tqdm\n",
    "for sample in tqdm(train_dataset):\n",
    "    try:\n",
    "        table_dict = json.loads(sample['table'])\n",
    "        df = pd.DataFrame(table_dict[\"data\"], columns=table_dict[\"columns\"])\n",
    "    except:\n",
    "        continue\n",
    "    sample['df'] = df\n",
    "    processed_sample = preprocessor(sample)\n",
    "    samples.append(processed_sample)\n",
    "train_dataset = Dataset.from_list(samples)\n",
    "# train_dataset.save_to_disk(data_args.save_path)\n",
    "train_dataset.shuffle(seed=42)\n",
    "eval_dataset = None\n",
    "# filter out training sample that token length larger than 10000\n",
    "train_dataset = train_dataset.filter(lambda x: len(x['input_ids']) <= 6000, num_proc=32)  \n",
    "print(len(train_dataset))\n",
    "# for sample in train_dataset:\n",
    "#     sample = sample_preprocessor(sample)\n",
    "#     print(len(sample['input_ids']), len(sample['label_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,B,C\n",
      "1,2,3\n",
      "4,5,6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['A', 'B', 'C'], data=[[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "string = df.iloc[:2].to_csv(index=False, header=True)\n",
    "print(string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LIU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
